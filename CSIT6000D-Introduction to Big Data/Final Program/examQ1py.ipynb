{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic 0.897591551362\n",
      "SVM 0.89294700044\n",
      "Random Forest 0.896487801301\n",
      "Decision tree 0.869279078864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN 0.896928323473\n",
      "Naive Bayes 0.810443455728\n",
      "Gradient Boosting tree 0.896709284702\n",
      "['default', 'housing', 'loan', 'norm_age', 'norm_pday', 'norm_balance', 'norm_duration', 'norm_campaign', 'norm_previous', 'job_admin.', 'job_blue-collar', 'job_entrepreneur', 'job_housemaid', 'job_management', 'job_retired', 'job_self-employed', 'job_services', 'job_student', 'job_technician', 'job_unemployed', 'job_unknown', 'marital_divorced', 'marital_married', 'marital_single', 'education_primary', 'education_secondary', 'education_tertiary', 'education_unknown', 'day_1', 'day_2', 'day_3', 'day_4', 'day_5', 'day_6', 'day_7', 'day_8', 'day_9', 'day_10', 'day_11', 'day_12', 'day_13', 'day_14', 'day_15', 'day_16', 'day_17', 'day_18', 'day_19', 'day_20', 'day_21', 'day_22', 'day_23', 'day_24', 'day_25', 'day_26', 'day_27', 'day_28', 'day_29', 'day_30', 'day_31', 'month_apr', 'month_aug', 'month_dec', 'month_feb', 'month_jan', 'month_jul', 'month_jun', 'month_mar', 'month_may', 'month_nov', 'month_oct', 'month_sep', 'poutcome_failure', 'poutcome_other', 'poutcome_success', 'poutcome_unknown', 'contact_cellular', 'contact_telephone', 'contact_unknown']\n",
      "[ 0.00438378  0.02167567  0.00976694  0.05842827  0.01993273  0.05576948\n",
      "  0.15940201  0.04076025  0.01302649  0.01335713  0.01483639  0.00626474\n",
      "  0.00404892  0.01471822  0.01137926  0.00556278  0.00918387  0.00546222\n",
      "  0.01761295  0.0040996   0.0029703   0.01453317  0.01863345  0.0121171\n",
      "  0.01056825  0.01400072  0.01332259  0.0052399   0.0038054   0.0070004\n",
      "  0.00552448  0.00625871  0.0100056   0.0072775   0.0071398   0.00627897\n",
      "  0.00769772  0.00530075  0.00787477  0.00683621  0.00727501  0.00722948\n",
      "  0.00784433  0.00890709  0.00629565  0.00942102  0.00568295  0.00668539\n",
      "  0.00623567  0.00761003  0.0049067   0.00505974  0.00466005  0.00723905\n",
      "  0.00505604  0.00763253  0.00427016  0.00856173  0.00236727  0.00927039\n",
      "  0.0106397   0.0022186   0.00794048  0.00384912  0.00844818  0.01216388\n",
      "  0.00920233  0.01191151  0.00890566  0.0184514   0.00515352  0.01176206\n",
      "  0.0053482   0.04614359  0.01727077  0.01113922  0.00582808  0.00935592]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from numpy import set_printoptions\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn import cross_validation\n",
    "\n",
    "bank = pd.read_csv(\"/Users/jiefenghou/Documents/bank.csv\", sep=\";\")\n",
    "\n",
    "#print(final_file.head(5))\n",
    "\n",
    "#normailize age\n",
    "\n",
    "age = bank[['age']]\n",
    "\n",
    "stand_scaler = StandardScaler().fit(age)\n",
    "stand_rescaled = stand_scaler.transform(age)\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "rescale_dai = scaler.fit_transform(stand_rescaled)\n",
    "bank['norm_age'] = rescale_dai\n",
    "bank = bank.drop(\"age\", axis=1)\n",
    "\n",
    "pday = bank[['pdays']]\n",
    "\n",
    "stand_scaler = StandardScaler().fit(pday)\n",
    "stand_rescaled = stand_scaler.transform(pday)\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "rescale_dai = scaler.fit_transform(stand_rescaled)\n",
    "bank['norm_pday'] = rescale_dai\n",
    "bank = bank.drop(\"pdays\", axis=1)\n",
    "\n",
    "\n",
    "balance = bank[['balance']]\n",
    "\n",
    "stand_scaler = StandardScaler().fit(balance)\n",
    "stand_rescaled = stand_scaler.transform(balance)\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "rescale_dai = scaler.fit_transform(stand_rescaled)\n",
    "bank['norm_balance'] = rescale_dai\n",
    "bank = bank.drop(\"balance\", axis=1)\n",
    "\n",
    "\n",
    "duration = bank[['duration']]\n",
    "\n",
    "stand_scaler = StandardScaler().fit(duration)\n",
    "stand_rescaled = stand_scaler.transform(duration)\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "rescale_dai = scaler.fit_transform(stand_rescaled)\n",
    "bank['norm_duration'] = rescale_dai\n",
    "bank = bank.drop(\"duration\", axis=1)\n",
    "\n",
    "\n",
    "campaign = bank[['campaign']]\n",
    "\n",
    "stand_scaler = StandardScaler().fit(campaign)\n",
    "stand_rescaled = stand_scaler.transform(campaign)\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "rescale_dai = scaler.fit_transform(stand_rescaled)\n",
    "bank['norm_campaign'] = rescale_dai\n",
    "bank = bank.drop(\"campaign\", axis=1)\n",
    "\n",
    "previous = bank[['previous']]\n",
    "\n",
    "stand_scaler = StandardScaler().fit(previous)\n",
    "stand_rescaled = stand_scaler.transform(previous)\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "rescale_dai = scaler.fit_transform(stand_rescaled)\n",
    "bank['norm_previous'] = rescale_dai\n",
    "bank = bank.drop(\"previous\", axis=1)\n",
    "\n",
    "\n",
    "\n",
    "#bank.groupby('job').size()\n",
    "dummy_job = pd.get_dummies(bank[\"job\"], prefix=\"job\")\n",
    "bank = pd.concat([bank, dummy_job], axis=1)\n",
    "bank = bank.drop(\"job\", axis=1)\n",
    "\n",
    "\n",
    "dummy_marital = pd.get_dummies(bank[\"marital\"], prefix=\"marital\")\n",
    "bank = pd.concat([bank, dummy_marital], axis=1)\n",
    "bank = bank.drop(\"marital\", axis=1)\n",
    "\n",
    "\n",
    "dummy_education = pd.get_dummies(bank[\"education\"], prefix=\"education\")\n",
    "bank = pd.concat([bank, dummy_education], axis=1)\n",
    "bank = bank.drop(\"education\", axis=1)\n",
    "\n",
    "dummy_day = pd.get_dummies(bank[\"day\"], prefix=\"day\")\n",
    "bank = pd.concat([bank, dummy_day], axis=1)\n",
    "bank = bank.drop(\"day\", axis=1)\n",
    "\n",
    "dummy_month = pd.get_dummies(bank[\"month\"], prefix=\"month\")\n",
    "bank = pd.concat([bank, dummy_month], axis=1)\n",
    "bank = bank.drop(\"month\", axis=1)\n",
    "\n",
    "dummy_poutcome = pd.get_dummies(bank[\"poutcome\"], prefix=\"poutcome\")\n",
    "bank = pd.concat([bank, dummy_poutcome], axis=1)\n",
    "bank = bank.drop(\"poutcome\", axis=1)\n",
    "\n",
    "\n",
    "dummy_contact = pd.get_dummies(bank[\"contact\"], prefix=\"contact\")\n",
    "bank = pd.concat([bank, dummy_contact], axis=1)\n",
    "bank = bank.drop(\"contact\", axis=1)\n",
    "\n",
    "bank['default'] = bank['default'].map({'yes': 1, 'no': 0})\n",
    "\n",
    "bank['housing'] = bank['housing'].map({'yes': 1, 'no': 0})\n",
    "\n",
    "bank['loan'] = bank['loan'].map({'yes': 1, 'no': 0})\n",
    "\n",
    "\n",
    "bank['y'] = bank['y'].map({'yes': 1, 'no': 0})\n",
    "\n",
    "bank.to_csv('/Users/jiefenghou/Documents/final.csv')\n",
    "\n",
    "col = list(bank.columns.values)\n",
    "\n",
    "col.remove('y')\n",
    "\n",
    "\n",
    "\n",
    "kf = KFold(len(bank), 5, shuffle=True, random_state=1)\n",
    "lr = LogisticRegression()\n",
    "\n",
    "accuracies = cross_val_score(lr,bank[col], bank['y'], scoring=\"accuracy\", cv=kf)\n",
    "average_accuracy = sum(accuracies) / len(accuracies)\n",
    "\n",
    "#print('logistic', accuracies)\n",
    "print('logistic', average_accuracy)\n",
    "\n",
    "#lr = LogisticRegression()\n",
    "\n",
    "svc = SVC(kernel='linear')\n",
    "\n",
    "accuracies = cross_val_score(svc,bank[col], bank['y'], scoring=\"accuracy\", cv=kf)\n",
    "average_accuracy = sum(accuracies) / len(accuracies)\n",
    "\n",
    "#print(accuracies)\n",
    "print('SVM', average_accuracy)\n",
    "\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=23)  \n",
    "\n",
    "accuracies = cross_val_score(clf,bank[col], bank['y'], scoring=\"accuracy\", cv=kf)\n",
    "average_accuracy = sum(accuracies) / len(accuracies)\n",
    "\n",
    "#print(accuracies)\n",
    "print('Random Forest', average_accuracy)\n",
    "\n",
    "\n",
    "dt = DecisionTreeClassifier()\n",
    "accuracies = cross_val_score(dt,bank[col], bank['y'], scoring=\"accuracy\", cv=kf)\n",
    "average_accuracy = sum(accuracies) / len(accuracies)\n",
    "\n",
    "#print(accuracies)\n",
    "print('Decision tree', average_accuracy)\n",
    "\n",
    "\n",
    "nelf = MLPClassifier(solver='adam', hidden_layer_sizes=(5, 2), alpha= 0.2)\n",
    "accuracies = cross_val_score(nelf,bank[col], bank['y'], scoring=\"accuracy\", cv=kf)\n",
    "average_accuracy = sum(accuracies) / len(accuracies)\n",
    "\n",
    "#print(accuracies)\n",
    "print('NN', average_accuracy)\n",
    "\n",
    "\n",
    "naby = GaussianNB()\n",
    "\n",
    "accuracies = cross_val_score(naby,bank[col], bank['y'], scoring=\"accuracy\", cv=kf)\n",
    "average_accuracy = sum(accuracies) / len(accuracies)\n",
    "\n",
    "#print(accuracies)\n",
    "print('Naive Bayes', average_accuracy)\n",
    "\n",
    "\n",
    "gbc = GradientBoostingClassifier()\n",
    "\n",
    "accuracies = cross_val_score(gbc,bank[col], bank['y'], scoring=\"accuracy\", cv=kf)\n",
    "average_accuracy = sum(accuracies) / len(accuracies)\n",
    "\n",
    "#print(accuracies)\n",
    "print('Gradient Boosting tree', average_accuracy)\n",
    "#bank.groupby('marital').size()\n",
    "#bank.groupby('default').size()\n",
    "#bank.groupby('housing').size()\n",
    "#bank.groupby('loan').size()\n",
    "#bank.groupby('contact').size()\n",
    "#bank.groupby('poutcome').size()\n",
    "\n",
    "#print(bank)\n",
    "\n",
    "\n",
    "#======================= Feature Importance\n",
    "\n",
    "model = ExtraTreesClassifier()\n",
    "model.fit(bank[col], bank['y'])\n",
    "print (col)\n",
    "print(model.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
